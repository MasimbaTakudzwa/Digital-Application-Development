{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LLP109: Digital Application Development \n",
    "# `Lecture 6 - Python Practice (Pandas)`\n",
    "\n",
    "\n",
    "Pandas builds on top of Numpy to ease managing heterogeneous data sets. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python (http://pandas.pydata.org/)\n",
    "\n",
    "\n",
    "This tutorial covers the following topics:\n",
    "\n",
    "- Pandas data structures\n",
    "- DataFrame Basic Functionality\n",
    "- Indexing and slicing DataFrames\n",
    "- Dropping data from a dataFrame\n",
    "- Modifying dataFrames\n",
    "- Handling missing data\n",
    "- Grouping and aggregation of data\n",
    "- Writing data frames to CSV files\n",
    "\n",
    "## 1. Pandas Data Structures\n",
    "Pandas is build around the following data structures\n",
    "\n",
    "- `Series` represent 1 dimensional datasets as subclass of Numpy's ndarray\n",
    "- `DataFrame` represent 2 dimensional data sets as list of Series\n",
    "- `Panel` represents higher dimensional data as dictionaries of DataFrame's. We do not discuss Panel's here.\n",
    "\n",
    "For all data structures, labels/indices can be defined per row and column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Series: labelled arrays\n",
    "Series is a one-dimensional labeled array capable of holding any data type (integers, strings, ﬂoating point numbers,Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a Series is to call:\n",
    "\n",
    "- Series(data, index=index)\n",
    "\n",
    "data may be a dict, a numpy.ndarray or a sclar value\n",
    "\n",
    "### Creating a series:\n",
    "### 1- With a default index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # we need numpy\n",
    "import pandas as pd #import pandas\n",
    "\n",
    "\n",
    "values = np.array([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.0599, 8.0]) #create numpy array\n",
    "ser = pd.Series(values) # now create series\n",
    "print (ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With a customisied index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets put some index on the data\n",
    "#indices will be great later on when accessing datas\n",
    "#indices represent unique identifiers for rows\n",
    "values = np.array([2.0, 1.0, 5.0, 0.97, 3.0, 10.0, 0.0599, 8.0])\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "ser = pd.Series(data=values, index=labels)#values and labels must have the same dimension\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating a heterogeneous series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craeting a heterogeneous series\n",
    "movie_rating = {\n",
    "    'age': 1,\n",
    "    'gender': 'F',\n",
    "    'genres': 'Drama',\n",
    "    'movie_id': 1193,\n",
    "    'occupation': 10,\n",
    "    'rating': 5,\n",
    "    'timestamp': 978300760,\n",
    "    'title': \"One Flew Over the Cuckoo's Nest (1975)\",\n",
    "    'user_id': 1,\n",
    "    'zip': '48067'\n",
    "    }\n",
    "ser = pd.Series(movie_rating)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing series index  and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the index\n",
    "ser.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the value\n",
    "ser.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. DataFrame: a Series of Series\n",
    "Pandas DataFrame is a 2 dimensional labeled data structure with columns of potentially different types. Similar to\n",
    "\n",
    "a spreadsheet\n",
    "relational database table\n",
    "a dictionary of series\n",
    "\n",
    "## Creating DataFrame's\n",
    "\n",
    "DataFrame's can be created from\n",
    "\n",
    "dict of Series\n",
    "dict of ndarrays\n",
    "structured or record arrays\n",
    "from a list of dicts\n",
    "From a dict of tuples\n",
    "From a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict of series\n",
    "import pandas as pd\n",
    "d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "    'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df = pd.DataFrame(d)\n",
    "print (df)\n",
    "\n",
    "print (\"Index:\", df.index)\n",
    "print (\"Columns:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict of lists\n",
    "d = {'one' : [1., 2., 3., 4.],\n",
    "    'two' :  [1., 2., 3., 4.]}\n",
    "df= pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 'one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#form a list of dicts\n",
    "data2 = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]\n",
    "df= pd.DataFrame(data2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a file: \n",
    "Pandas provides helper functions to read data from various file formats like CSV, Excel spreadsheets, HTML tables, JSON, SQL, and more. Data from the file is read and stored in a `DataFrame` object. We typically use the `_df` suffix in the variable names for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DataFrame Basic Functionality\n",
    "- Accessing head and tails via `DataFrame.head` and `DataFrame.tail`\n",
    "-  Information of a DataFrame using `DataFrame.info` and `DataFrame.describe`\n",
    "- Column values: `DataFrame.value_counts`, `DataFrame.unique` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Head and Tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "Descriptive Statistics sumarizes the underlying distribution of data values through statistical values like mean, variance etc.\n",
    "\n",
    "We can view some basic information about the data frame using the `.info` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4), columns=['A', 'B', 'C', 'D']) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that each column contains values of a specific data type. You can view statistical information for numerical columns (mean, standard deviation, minimum/maximum values, and the number of non-empty values) using the `.describe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some examples\n",
    "print (df.max())\n",
    "print (\"========================================\")\n",
    "print (df.max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.idxmax(axis=0))\n",
    "print (\"============================\")\n",
    "print (df.idxmin(axis=0))\n",
    "print (\"============================\")\n",
    "print (df.idxmax(axis=1))\n",
    "print (\"============================\")\n",
    "print (df.idxmin(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value counts and unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts()`allows to count the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one' : [1., 1., 2., 4.],\n",
    "    'two' :  [1., 2., 3., 4.]}\n",
    "df= pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['one'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['one'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Indexing and slicing DataFrames\n",
    "The first thing you might want to do is retrieve data from this data frame. To do this, it might help to understand the internal representation of data in a data frame. Conceptually, you can think of a dataframe as a dictionary of lists: keys are column names, and values are lists/arrays containing data for the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.randint(0, 10, size=(3,3))\n",
    "frame = pd.DataFrame(data, index=['r1', 'r2', 'r3'], columns=['c1', 'c2', 'c3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frame['c1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.drop('r1', axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving columns: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dictionary of lists analogy in mind, you can now guess how to retrieve data from a data frame. For example, we can get a list of values from a specific column using the [] indexing notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve one column\n",
    "frame['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of using the indexing notation [], Pandas also allows accessing columns as properties of the dataframe using the . notation. However, this method only works for columns whose names do not contain spaces or special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like arrays, you can retrieve a specific value with a series using the indexing notation `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['c1']['r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, you can also pass a list of columns within the indexing notation [] to access a subset of the data frame with just the given columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve multiple columns\n",
    "slice_df= frame[['c1', 'c3']]\n",
    "slice_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data frame slice_df is simply a \"view\" of the original data frame . Both point to the same data in the computer's memory. Changing any values inside one of them will also change the respective values in the other. Sharing data between data frames makes data manipulation in Pandas blazing fast. You needn't worry about the overhead of copying thousands or millions of rows every time you want to create a new data frame by operating on an existing one.\n",
    "\n",
    "Sometimes you might need a full copy of the data frame using `.copy()` method, in which case you can use the copy method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving rows: \n",
    "To access a specific row of data, Pandas provides the `.loc` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive row by name\n",
    "frame.loc['r1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive multiple rows by name\n",
    "frame.loc[['r1','r3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve a single cell\n",
    "frame['c1']['r1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select across rows and columns by label\n",
    "frame.loc[['r1', 'r2'], ['c1', 'c2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.loc['r1':'r3', 'c1':'c3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.iloc[:2, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking: Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame['c1']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame<5] = -1\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECOMMENDED:** Always use loc and iloc to reduce ambiguity, specially with DataFrames with numeric indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Population': [35.467, 63.951, 80.94 , 60.665, 127.061, 64.511, 318.523],\n",
    "    'GDP': [\n",
    "        1785387,\n",
    "        2833687,\n",
    "        3874437,\n",
    "        2167744,\n",
    "        4602367,\n",
    "        2950039,\n",
    "        17348075\n",
    "    ],\n",
    "    'Surface Area': [\n",
    "        9984670,\n",
    "        640679,\n",
    "        357114,\n",
    "        301336,\n",
    "        377930,\n",
    "        242495,\n",
    "        9525067\n",
    "    ],\n",
    "    'HDI': [\n",
    "        0.913,\n",
    "        0.888,\n",
    "        0.916,\n",
    "        0.873,\n",
    "        0.891,\n",
    "        0.907,\n",
    "        0.915\n",
    "    ],\n",
    "    'Continent': [\n",
    "        'America',\n",
    "        'Europe',\n",
    "        'Europe',\n",
    "        'Europe',\n",
    "        'Asia',\n",
    "        'Europe',\n",
    "        'America'\n",
    "    ]\n",
    "}, columns=['Population', 'GDP', 'Surface Area', 'HDI', 'Continent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames also have indexes. As you can see in the \"table\" above, pandas has assigned a numeric, autoincremental index automatically to each \"row\" in our DataFrame. In our case, we know that each row represents a country, so we'll just reassign the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = [\n",
    "    'Canada',\n",
    "    'France',\n",
    "    'Germany',\n",
    "    'Italy',\n",
    "    'Japan',\n",
    "    'United Kingdom',\n",
    "    'United States',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index of the returned Series is the same as the DataFrame one. And its name is the name of the column. \n",
    "Multiple columns can also be selected similarly to numpy and Series. In this case, the result is another DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Population', 'GDP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing works differently, it acts at \"row level\", and can be counter intuitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row level selection works better with loc and iloc which are recommended over regular \"direct slicing\" (df[:]).\n",
    "\n",
    "loc selects rows matching the given index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Italy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['France': 'Italy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second \"argument\", you can pass the column(s) you'd like to select:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['France': 'Italy', ['Population', 'GDP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0, 1, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, [0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 1:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking: Boolen indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Population'] > 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boolean matching is done at Index level, so you can filter by any row, as long as it contains the right indexes. Column selection still works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Population'] > 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Population'] > 70, 'Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Population'] > 70, ['Population', 'GDP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = df['Population']\n",
    "population.min(), population.max()\n",
    "population.sum()\n",
    "population.sum() / len(population)\n",
    "population.mean()\n",
    "population.median()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Dropping data from a dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposed to the concept of selection, we have \"dropping\". Instead of pointing out which values you'd like to select you could point which ones you'd like to drop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Canada', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Canada', 'Japan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Population', 'HDI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Italy', 'Canada'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Population', 'HDI'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these drop methods return a new DataFrame. If you'd like to modify it \"in place\", you can use the inplace attribute (there's an example below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modifying DataFrames\n",
    "It's simple and intuitive, You can add columns, or replace values for columns without issues:\n",
    "\n",
    " ## Adding a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.Series(\n",
    "    ['French', 'German', 'Italian'],\n",
    "    index=['France', 'Germany', 'Italy'],\n",
    "    name='Language'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Language'] = langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Replacing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Language'] = 'English'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GDP Per Capita'] = df['GDP'] / df['Population']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        'HDI': 'Human Development Index',\n",
    "        'Anual Popcorn Consumption': 'APC'\n",
    "    }, index={\n",
    "        'United States': 'USA',\n",
    "        'United Kingdom': 'UK',\n",
    "        'Argentina': 'AR'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(pd.Series({\n",
    "    'Population': 3,\n",
    "    'GDP': 5\n",
    "}, name='China'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly set the new index and values to the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['China'] = pd.Series({'Population': 1_400_000_000, 'Continent': 'Asia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()\n",
    "df.set_index('Population')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting rows using column values\n",
    "\n",
    "The rows can also be sorted by a specific column using `.sort_values`. Let's sort to identify the days with the highest number of cases, then chain it with the `head` method to list just the first ten results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Population', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Grouping and aggregating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports grouping data frames for particular columns similar to a SQL group by clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df.groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'a' : ['one','one','two','three','two','one','six'],\n",
    "                 'b' : ['x','y','y','x','y','x','x'],\n",
    "                 'c' : np.random.randn(7)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('a') #creates a groupby object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a new data frame that uses unique values from the column passed to groupby as the index. Grouping and aggregation is a powerful method for progressively summarizing data into smaller data frames.\n",
    "\n",
    "Instead of aggregating by sum, you can also aggregate by other measures like mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gropuing requires an aggregate function\n",
    "df2.groupby('a'). #creates a groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works on multiple levels\n",
    "df2.groupby(['a','b']).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Dealing with missing values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "wh.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed something strange in the output of the describe method. First, the minimum value in both precipitation and snow depth fields is -1. The special value -1 means that on that day there was absolutely no snow or rain, whereas the value 0 might indicate that the value was close to zero. Secondly, the snow depth column has count 358, whereas the other columns have count 365, one measurement/value for each day of the year. How is this possible? Every field in a DataFrame should have the same number of rows. Let’s use the unique method of the Series object to find out, which different values are used in this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh[\"Snow depth (cm)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh[\"Snow depth (cm)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The float type allows a special value nan (Not A Number), in addition to normal floating point numbers. This value can represent the result from an illegal operation. For example, the operation 0/0 can either cause an exception to occur or just silently produce a nan. In Pandas nan can be used to represent a missing value. In the weather DataFrame the nan value tells us that the measurement from that day is not available, possibly due to a broken measuring instrument or some other problem.\n",
    "\n",
    "The missing values can be located with the isnull method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.isnull()      # returns a boolean mask DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not very useful as we cannot directly use the mask to index the DataFrame. We can, however, combine it with the any method to find out all the rows that contain at least one missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh[wh.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notnull method works conversively to the isnull method.\n",
    "\n",
    "The dropna method of a DataFrame drops columns or rows that contain missing values from the DataFrame, depending on the axis parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.dropna().shape   # Default axis is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.dropna(axis=1).shape # Drops the columns containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fillna method allows to fill the missing values with some constant or interpolated values. The method parameter can be:\n",
    "\n",
    "- None: use the given positional parameter as the constant to fill missing values with\n",
    "- ffill: use the previous value to fill the current value\n",
    "- bfill: use the next value to fill the current value\n",
    "- Replace it with 0.\n",
    "- Replace it with the average of the entire column\n",
    "- Replace it with the average of the values on the previous & next date\n",
    "- Discard the row entirely\n",
    "\n",
    "The choice of the method depends on the nature of missing data. \n",
    "\n",
    "For example, for the weather data we could use forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.fillna(method='ffill', inplace= True)\n",
    "wh[wh.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame to a file: \n",
    "To write the data from the data frame into a file, we can use the `to_csv` function. The to_csv function also includes an additional column for storing the index of the dataframe by default. We pass index=None to turn off this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.to_csv('wheather_modified.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References: \n",
    "- Pandas Documentation https://pandas.pydata.org/pandas-docs/stable/pandas.pdf\n",
    "- https://nbviewer.jupyter.org/github/mgrani/LODA-lecture-notes-on-data-analysis/blob/master/I.Data-Science-in-Python/DSiP-6-Pandas.ipynb\n",
    "- https://github.com/ine-rmotr-curriculum/freecodecamp-intro-to-pandas/blob/master/3%20-%20Pandas%20-%20DataFrames.ipynb\n",
    "- https://saskeli.github.io/data-analysis-with-python-summer-2019/pandas2.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
